{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model.dataloader import NinaProDatasetLoader, NearlabDatasetLoader\n",
    "from model.nina_helper import *\n",
    "import torch\n",
    "import pandas as pd\n",
    "from sklearn.utils import shuffle\n",
    "from scipy import signal\n",
    "import os\n",
    "from model.utils import list_files\n",
    "from model.model import CNet2D\n",
    "\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_nearlab = \"E:/Dennis_Bachelor/Bachelor_Thesis-main/src/data/nearlab/8features/person\"\n",
    "path_ninapro = \"E:/Dennis_Bachelor/Bachelor_Thesis-main/src/data/ninapro/DB2/person\"\n",
    "results_ninapro = \"E:/Dennis_Bachelor/Bachelor_Thesis-main/src/results/ninapro\"\n",
    "results_nearlab = \"E:/Dennis_Bachelor/Bachelor_Thesis-main/src/results/nearlab\"\n",
    "versions = [\"Softmax\", \"GLVQ\", \"GMLVQ\"]\n",
    "n_shots = [1, 5, 10]\n",
    "prototypes_per_class = [1, 2, 4, 8]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Nearlab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load in all Subject Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Runs all models with all subjects expect one as training and one as testing\n",
    "def run_model_all_subjects():\n",
    "    for person in range(1, 12):\n",
    "        train_paths = [x for x in list_files(path_nearlab + f\"{person}\", \"csv\")]\n",
    "        test_paths = []\n",
    "        for person2 in range(1, 12):\n",
    "            if person2 != person:\n",
    "                test_paths.append([train_paths.append(x) for x in list_files(path_nearlab + f\"{person2}\", \"csv\")])\n",
    "        \n",
    "        data = NearlabDatasetLoader(train_paths, test_paths)\n",
    "        X_train, y_train, X_val, y_val, X_test, y_test = data.load_data()\n",
    "\n",
    "        for version in versions:\n",
    "            # Recommended Settings\n",
    "            current_model = CNet2D(version=version, epochs=400, batch_size=128, learning_rate=0.0002)\n",
    "            history = current_model.fit(X_train, y_train, 10, X_val, y_val)\n",
    "            # Add accuracy of model to history\n",
    "            history[\"accuracy\"] = current_model.evaluate_model(X_test, y_test)\n",
    "            # Checks if folder exists, if not creates it\n",
    "            if not os.path.exists(results_nearlab + f\"/person{person}/\"):\n",
    "                os.makedirs(results_nearlab + f\"/person{person}/\")\n",
    "            # Save model\n",
    "            current_model.save_model(results_nearlab + f\"/person{person}/model_{version}_Subject_{person}.pt\")\n",
    "            # Save history\n",
    "            current_model.save_history_csv(history, results_nearlab + f\"/person{person}/history_{version}_Subject_{person}.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Runs all models with all hand-orientation combinations on each subject where 2 files are used for training and 1 for testing\n",
    "def run_model_all_orientations(num_prototype_per_class):\n",
    "    for person in range(1, 12):\n",
    "        for orien in range(1, 4):\n",
    "            all_files = list_files(path_nearlab + f\"{person}\", \"csv\")\n",
    "            test_paths = [all_files[orien]]\n",
    "            train_paths = [x for x in all_files if x not in test_paths]\n",
    "            data = NearlabDatasetLoader(train_paths, test_paths)\n",
    "            X_train, y_train, X_val, y_val, X_test, y_test = data.load_data()\n",
    "\n",
    "            for version in versions:\n",
    "                # Recommended Settings\n",
    "                current_model = CNet2D(version=version, epochs=400, batch_size=128, learning_rate=0.0002, num_prototypes_per_class=num_prototype_per_class)\n",
    "                history = current_model.fit(X_train, y_train, 10, X_val, y_val)\n",
    "                # Add accuracy of model to history\n",
    "                history[\"accuracy\"] = current_model.evaluate_model(X_test, y_test)\n",
    "                # Checks if folder exists, if not creates it\n",
    "                if not os.path.exists(results_nearlab + f\"/person{person}/\"):\n",
    "                    os.makedirs(results_nearlab + f\"/person{person}/\")\n",
    "                # Save model\n",
    "                current_model.save_model(results_nearlab + f\"/person{person}/model_{version}_Orientation_{orien}_Prototypes_{num_prototype_per_class}.pt\")\n",
    "                # Save history\n",
    "                current_model.save_history_csv(history, results_nearlab + f\"/person{person}/history_{version}_Orientation_{orien}_Prototypes_{num_prototype_per_class}.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Runs k shot FSL on all subjects with 2 files used for training and 1 for testing\n",
    "def run_k_shot_FSL(k_shots):\n",
    "    for person in range(1, 12):\n",
    "        all_files = list_files(path_nearlab + f\"{person}\", \"csv\")\n",
    "        test_paths = [all_files[2]]\n",
    "        train_paths = [x for x in all_files if x not in test_paths]\n",
    "        data = NearlabDatasetLoader(train_paths, test_paths)\n",
    "        X_train, y_train, X_val, y_val, X_test, y_test = data.load_data()\n",
    "        # Select random class\n",
    "        unique_classes = np.unique(y_train)\n",
    "        random_class = np.random.choice(unique_classes)\n",
    "        # Select all classes from X_train except the random class\n",
    "        X_train_filtered = X_train[y_train != random_class]\n",
    "        y_train_filtered = y_train[y_train != random_class]\n",
    "        # Select all classes from X_val except the random class\n",
    "        X_val = X_val[y_val != random_class]\n",
    "        y_val = y_val[y_val != random_class]\n",
    "        # Select k_shots samples from X_train\n",
    "        few_shot_mask = y_test == random_class\n",
    "        few_shot_indices = np.random.choice(np.where(few_shot_mask)[0], k_shots, replace=False)\n",
    "        few_shot_X = X_test[few_shot_indices]\n",
    "        \n",
    "        for version in versions:\n",
    "            # Recommended Settings from paper\n",
    "            current_model = CNet2D(version=version, epochs=400, batch_size=128, learning_rate=0.0002)\n",
    "            history = current_model.fit(X_train_filtered, y_train_filtered, 10, X_val, y_val)\n",
    "            # Add accuracy of model to history\n",
    "            current_model.add_new_class(few_shot_X)\n",
    "            current_model.optimize_new_prototypes(few_shot_X, epochs=5)\n",
    "            history[\"accuracy\"] = current_model.evaluate_model(X_test, y_test)\n",
    "            # Checks if folder exists, if not creates it\n",
    "            if not os.path.exists(results_nearlab + f\"/person{person}/\"):\n",
    "                os.makedirs(results_nearlab + f\"/person{person}/\")\n",
    "            # Save model\n",
    "            current_model.save_model(results_nearlab + f\"/person{person}/model_{version}_K_Shot_{k_shots}.pt\")\n",
    "            # Save history\n",
    "            current_model.save_history_csv(history, results_nearlab + f\"/person{person}/history_{version}_K_Shot_{k_shots}.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ninapro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of EMG data: (2553289, 12)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Length of values (5106578) does not match length of index (2553289)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 5\u001b[0m\n\u001b[1;32m      1\u001b[0m folder_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/Users/dennisschielke/Desktop/Uni/Bachelor_Thesis/src/data/ninapro/DB2/person1/\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      3\u001b[0m ninapro \u001b[38;5;241m=\u001b[39m NinaProDatasetLoader(folder_path, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m512\u001b[39m, \u001b[38;5;241m128\u001b[39m)\n\u001b[0;32m----> 5\u001b[0m X_train, y_train, X_test, y_test \u001b[38;5;241m=\u001b[39m \u001b[43mninapro\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43msplit_method\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mbalanced\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_reps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28mprint\u001b[39m(X_train\u001b[38;5;241m.\u001b[39mshape)\n",
      "File \u001b[0;32m~/Desktop/Uni/Bachelor_Thesis/src/model/dataloader.py:204\u001b[0m, in \u001b[0;36mNinaProDatasetLoader.load_data\u001b[0;34m(self, split_method, test_reps)\u001b[0m\n\u001b[1;32m    202\u001b[0m \u001b[38;5;66;03m# Convert to Dataframe for the filter function\u001b[39;00m\n\u001b[1;32m    203\u001b[0m emg_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(normalized_emg, columns\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mchannel_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(normalized_emg\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m])])\n\u001b[0;32m--> 204\u001b[0m emg_df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstimulus\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m data[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmove\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    205\u001b[0m emg_df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrepetition\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m data[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrep\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    207\u001b[0m filtered_emg \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfilter_data(emg_df, f\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m10\u001b[39m, \u001b[38;5;241m450\u001b[39m), butterworth_order\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4\u001b[39m, btype\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbandpass\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/pie/lib/python3.8/site-packages/pandas/core/frame.py:3980\u001b[0m, in \u001b[0;36mDataFrame.__setitem__\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   3977\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_setitem_array([key], value)\n\u001b[1;32m   3978\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   3979\u001b[0m     \u001b[38;5;66;03m# set column\u001b[39;00m\n\u001b[0;32m-> 3980\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_set_item\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/pie/lib/python3.8/site-packages/pandas/core/frame.py:4174\u001b[0m, in \u001b[0;36mDataFrame._set_item\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   4164\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_set_item\u001b[39m(\u001b[38;5;28mself\u001b[39m, key, value) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   4165\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   4166\u001b[0m \u001b[38;5;124;03m    Add series to DataFrame in specified column.\u001b[39;00m\n\u001b[1;32m   4167\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4172\u001b[0m \u001b[38;5;124;03m    ensure homogeneity.\u001b[39;00m\n\u001b[1;32m   4173\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 4174\u001b[0m     value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sanitize_column\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4176\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   4177\u001b[0m         key \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\n\u001b[1;32m   4178\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m value\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   4179\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_extension_array_dtype(value)\n\u001b[1;32m   4180\u001b[0m     ):\n\u001b[1;32m   4181\u001b[0m         \u001b[38;5;66;03m# broadcast across multiple columns if necessary\u001b[39;00m\n\u001b[1;32m   4182\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mis_unique \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns, MultiIndex):\n",
      "File \u001b[0;32m~/miniconda3/envs/pie/lib/python3.8/site-packages/pandas/core/frame.py:4915\u001b[0m, in \u001b[0;36mDataFrame._sanitize_column\u001b[0;34m(self, value)\u001b[0m\n\u001b[1;32m   4912\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _reindex_for_setitem(Series(value), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex)\n\u001b[1;32m   4914\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_list_like(value):\n\u001b[0;32m-> 4915\u001b[0m     \u001b[43mcom\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequire_length_match\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4916\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m sanitize_array(value, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, allow_2d\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/miniconda3/envs/pie/lib/python3.8/site-packages/pandas/core/common.py:571\u001b[0m, in \u001b[0;36mrequire_length_match\u001b[0;34m(data, index)\u001b[0m\n\u001b[1;32m    567\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    568\u001b[0m \u001b[38;5;124;03mCheck the length of data matches the length of the index.\u001b[39;00m\n\u001b[1;32m    569\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    570\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(data) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(index):\n\u001b[0;32m--> 571\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    572\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLength of values \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    573\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(data)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m) \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    574\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdoes not match length of index \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    575\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(index)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    576\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: Length of values (5106578) does not match length of index (2553289)"
     ]
    }
   ],
   "source": [
    "folder_path = \"/Users/dennisschielke/Desktop/Uni/Bachelor_Thesis/src/data/ninapro/DB2/person1/\"\n",
    "\n",
    "ninapro = NinaProDatasetLoader(folder_path, 1, 2, 512, 128)\n",
    "\n",
    "X_train, y_train, X_test, y_test = ninapro.load_data(split_method=\"balanced\", test_reps=2)\n",
    "\n",
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4928, 10, 512])\n"
     ]
    }
   ],
   "source": [
    "path_nearlab = \"/Users/dennisschielke/Desktop/Uni/Bachelor_Thesis/src/data/nearlab/8features/person1\"\n",
    "file_paths_nearlab = list_files(path_nearlab, \"csv\")\n",
    "version = \"GMLVQ\"\n",
    "data = NearlabDatasetLoader(file_paths_nearlab[:2], file_paths_nearlab[2:])\n",
    "X_train, y_train, X_test, y_test = data.load_data(split_method=\"repetition_wise\")\n",
    "\n",
    "print(X_train.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pie",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model.dataloader import NinaProDatasetLoader, NearlabDatasetLoader\n",
    "from model.nina_helper import *\n",
    "import torch\n",
    "import pandas as pd\n",
    "from sklearn.utils import shuffle\n",
    "from scipy import signal\n",
    "from model.utils import list_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NinaProDatasetLoader:\n",
    "    \"\"\"\n",
    "    NinaProDatasetLoader class to load and preprocess NinaPro dataset.\n",
    "    \n",
    "    Parameters:\n",
    "    ----------\n",
    "    folder_path : str\n",
    "        Path to the folder containing NinaPro database files\n",
    "    subject : int\n",
    "        Subject number to load (1-27 for DB1, 1-40 for DB2)\n",
    "    database : int\n",
    "        Which NinaPro database to use (1 or 2)\n",
    "    window_length : int\n",
    "        Length of the sliding window in samples\n",
    "    window_increment : int\n",
    "        Increment between consecutive windows in samples\n",
    "    rest_length_cap : int, optional\n",
    "        Number of seconds of rest data to keep before/after movement (default: 5)\n",
    "    \"\"\"\n",
    "    def __init__(self, folder_path, subject, database, window_length, window_increment, rest_length_cap = 5):\n",
    "        \n",
    "        self.folder_path = folder_path\n",
    "        self.subject = subject\n",
    "        self.database = database\n",
    "        self.window_length = window_length\n",
    "        self.window_increment = window_increment\n",
    "        self.rest_length_cap = rest_length_cap\n",
    "        \n",
    "    def load_data(self, split_method = \"repetition_wise\", test_reps = 2):\n",
    "        \"\"\"\n",
    "        Load and preprocess the NinaPro dataset.\n",
    "        \n",
    "        Parameters:\n",
    "        ----------\n",
    "        split_method : str\n",
    "            Method to split the data (\"repetition_wise\" or \"balanced\")\n",
    "        test_reps : int\n",
    "            Number of repetitions to use for testing\n",
    "        \n",
    "        \"\"\"\n",
    "        # Load in Ninapro data based on database\n",
    "        if self.database == 1:\n",
    "            data = import_db1(self.folder_path, self.subject, self.rest_length_cap)\n",
    "        elif self.database == 2:\n",
    "            data = import_db2(self.folder_path, self.subject, self.rest_length_cap)\n",
    "        else:\n",
    "            raise ValueError(\"Database must be 1 or 2\")\n",
    "            \n",
    "        rep_ids = np.unique(data[\"rep\"])\n",
    "        rep_ids = rep_ids[rep_ids > 0]\n",
    "        \n",
    "        # Split into train test set\n",
    "        if split_method == \"repetition_wise\":\n",
    "            train_reps, test_reps = gen_split_rand(rep_ids, test_reps, 12, base=[2, 5])\n",
    "        elif split_method == \"balanced\":\n",
    "            train_reps, test_reps = gen_split_balanced(rep_ids, test_reps, base=[2, 5])\n",
    "        else:\n",
    "            raise ValueError(\"Split not included\")\n",
    "            \n",
    "        # Use first split if multiple were generated\n",
    "        train_reps = train_reps[0]\n",
    "        test_reps = test_reps[0]\n",
    "        \n",
    "        # Normalize data\n",
    "        normalized_emg = normalise_emg(data[\"emg\"], data[\"rep\"], train_reps)\n",
    "\n",
    "        # Convert to Dataframe for the filter function\n",
    "        emg_df = pd.DataFrame(normalized_emg, columns=[f\"channel_{i+1}\" for i in range(normalized_emg.shape[1])])\n",
    "        emg_df[\"stimulus\"] = data[\"move\"]\n",
    "        emg_df[\"repetition\"] = data[\"rep\"]\n",
    "\n",
    "        filtered_emg = self.filter_data(emg_df, f=(10, 450), butterworth_order=4, btype='bandpass')\n",
    "\n",
    "        emg_filtered = filtered_emg.values[:, :12]\n",
    "        \n",
    "        # Get windowed data for training set\n",
    "        X_train, y_train, _ = get_windows(\n",
    "            train_reps,\n",
    "            self.window_length,\n",
    "            self.window_increment,\n",
    "            emg_filtered,\n",
    "            data[\"move\"],\n",
    "            data[\"rep\"]\n",
    "        )\n",
    "        \n",
    "        # Get windowed data for test set\n",
    "        X_test, y_test, _ = get_windows(\n",
    "            test_reps,\n",
    "            self.window_length,\n",
    "            self.window_increment,\n",
    "            emg_filtered,\n",
    "            data[\"move\"],\n",
    "            data[\"rep\"]\n",
    "        )\n",
    "        \n",
    "        # Shuffle the data\n",
    "        X_train, y_train = shuffle(X_train, y_train, random_state=42)\n",
    "        X_test, y_test = shuffle(X_test, y_test, random_state=42)\n",
    "        \n",
    "        # Convert to PyTorch tensors\n",
    "        X_train = torch.FloatTensor(X_train).squeeze(-1)\n",
    "        y_train = torch.LongTensor(y_train)\n",
    "        X_test = torch.FloatTensor(X_test).squeeze(-1)\n",
    "        y_test = torch.LongTensor(y_test)\n",
    "        \n",
    "        return X_train, y_train, X_test, y_test\n",
    "    \n",
    "    # from https://github.com/parasgulati8/NinaPro-Helper-Library/blob/master/NinaPro_Utility.py\n",
    "    def filter_data(self, data, f, butterworth_order = 4, btype = 'lowpass'):\n",
    "        emg_data = data.values[:,:12]\n",
    "        \n",
    "        f_sampling = 2000\n",
    "        nyquist = f_sampling/2\n",
    "        if isinstance(f, int):\n",
    "            fc = f/nyquist\n",
    "        else:\n",
    "            fc = list(f)\n",
    "            for i in range(len(f)):\n",
    "                fc[i] = fc[i]/nyquist\n",
    "                \n",
    "        b,a = signal.butter(butterworth_order, fc, btype=btype)\n",
    "        transpose = emg_data.T.copy()\n",
    "        \n",
    "        for i in range(len(transpose)):\n",
    "            transpose[i] = (signal.lfilter(b, a, transpose[i]))\n",
    "        \n",
    "        filtered = pd.DataFrame(transpose.T)\n",
    "        filtered['stimulus'] = data['stimulus']\n",
    "        filtered['repetition'] = data['repetition']\n",
    "        \n",
    "        return filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model.model import CNet2D\n",
    "version=\"Softmax\"\n",
    "folder_path = \"/Users/dennisschielke/Desktop/Uni/Bachelor_Thesis/src/data/ninapro/DB2/person1/\"\n",
    "\n",
    "ninapro = NinaProDatasetLoader(folder_path, 1, 2, 400, 40)\n",
    "\n",
    "X_train, y_train, X_test, y_test = ninapro.load_data(split_method=\"balanced\", test_reps=2)\n",
    "\n",
    "current_model = CNet2D(version=version, epochs=1, num_classes=50, batch_size=128, dataset_type=\"NinaPro\")\n",
    "history = current_model.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47\n",
      " 48 49]\n"
     ]
    }
   ],
   "source": [
    "print(np.unique(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([88272, 400, 12, 1])\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_nearlab = \"/Users/dennisschielke/Desktop/Uni/Bachelor_Thesis/src/data/nearlab/8features/person1\"\n",
    "file_paths_nearlab = list_files(path_nearlab, \"csv\")\n",
    "\n",
    "data = NearlabDatasetLoader(file_paths_nearlab[:2], file_paths_nearlab[2:])\n",
    "X_train, y_train, X_test, y_test = data.load_data(split_method=\"repetition_wise\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4944, 10, 512])\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pie",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
